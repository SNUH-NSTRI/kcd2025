from typing import TypedDict, Optional
from langgraph.graph import StateGraph, END
import pandas as pd
import numpy as np
import shap
from datetime import datetime
import os
from openai import OpenAI
import json
import xgboost as xgb
import numpy as np
import joblib


# State ì •ì˜
class ExtubationPredictionState(TypedDict):
    """ì „ì²´ ì›Œí¬í”Œë¡œìš°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìƒíƒœ"""
    # ì…ë ¥ ë°ì´í„°
    patient_input: Optional[dict]  # ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°
    patient_data: Optional[pd.DataFrame]
    tagging_model: Optional[str]
    generation_model: Optional[str]

    # Ontology íƒœê¹… ê²°ê³¼
    ontology_features: Optional[dict]
    feature_matrix: Optional[np.ndarray]
    feature_names: Optional[list]

    # ML ëª¨ë¸ ë° ì˜ˆì¸¡ ê²°ê³¼
    model: Optional[xgb.Booster]
    prediction_result: Optional[dict]

    # SHAP ë¶„ì„ ê²°ê³¼
    shap_values: Optional[np.ndarray]
    shap_explanation: Optional[dict]

    # ìµœì¢… ë ˆí¬íŠ¸
    report: Optional[str]

    # ì—ëŸ¬ í•¸ë“¤ë§
    error: Optional[str]


# Node 1: ì‚¬ìš©ì ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
def process_user_input(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """
    ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ë°›ì€ í™˜ì ë°ì´í„° ì²˜ë¦¬
    """
    try:
        patient_input = state["patient_input"]

        # í•„ìˆ˜ feature ì²´í¬
        required_features = ['AGE', 'SEX', 'BMI', 'VENT_DUR', 'CHF', 'CVD', 'CPD', 'CKD', 'CLD', 'DM', 'CRRT', 'CVP', 'MAP', 'HR', 'RR', 'BT', 'SPO2', 'GCS', 'PH', 'PACO2', 'PAO2', 'HCO3', 'LACTATE', 'WBC', 'HB', 'PLT', 'SODIUM', 'POTASSIUM', 'CHLORIDE', 'BUN', 'CR', 'TB', 'PT', 'FIO2', 'PEEP', 'PPLAT', 'TV', 'obesity_importance',
       'advanced_age_importance', 'male_sex_importance',
       'high_fraction_of_inspired_oxygen_importance',
       'diabetes_mellitus_history_importance', 'acidosis_importance',
       'anemia_importance', 'elevated_blood_urea_nitrogen_importance',
       'tachycardia_importance', 'low_mean_arterial_pressure_importance']
        
        missing_features = [f for f in required_features if f not in patient_input]
        
        if missing_features:
            return {
                **state,
                "error": f"Missing required features: {missing_features}"
            }

        # DataFrameìœ¼ë¡œ ë³€í™˜ (1ê°œ í–‰)
        df = pd.DataFrame([patient_input])
        sex_map = {"M": 0, "F": 1, "F": 0, "M": 1, 0: 0, 1: 1}
        df["SEX"] = df["SEX"].map(sex_map).astype(float)

        # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ ì„ íƒ (ìˆœì„œ ìœ ì§€)
        df = df[required_features]
        required_cols = ["SODIUM", "CHLORIDE", "HCO3"]
        if all(col in df.columns for col in required_cols):
            df["ANION_GAP"] = df["SODIUM"] - df["CHLORIDE"] - df["HCO3"]

        print(f"  Features: {list(df.columns)}")

        return {
            **state,
            "patient_data": df,
            "error": None
        }

    except Exception as e:
        return {
            **state,
            "error": f"Input processing error: {str(e)}"
        }


# Node 2: Ontology Feature íƒœê¹… (LLM ì‚¬ìš©)
def tag_ontology_features(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """
    LLMì„ ì‚¬ìš©í•œ ì˜ë£Œ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ íŠ¹ì„± íƒœê¹…
    """
    try:
        df = state["patient_data"]

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(base_url="your_endpoint_url", api_key="your_api_key")

        # í™˜ì ë°ì´í„°ë¥¼ JSON í˜•íƒœë¡œ ë³€í™˜
        patient_records = df.to_dict(orient='records')
        # assert False

        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë„ˆëŠ” ì¤‘í™˜ìì‹¤ ì „ë¬¸ì˜ì´ì ì„ìƒ ë°ì´í„° ì „ë¬¸ê°€ì•¼.
ì•„ë˜ ë³€ìˆ˜ë“¤ì´ í™˜ìì˜ 'ë°œê´€ ì‹¤íŒ¨(Extubation Failure)' ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ íŒë‹¨í•´ì¤˜.

í™˜ì ë°ì´í„°:
{json.dumps(patient_records, indent=2, ensure_ascii=False)}

ì§ˆë¬¸:
1. obesity_importance
2. advanced_age_importance
3. male_sex_importance
4. high_fraction_of_inspired_oxygen_importance
5. diabetes_mellitus_history_importance
6. acidosis_importance
7. anemia_importance
8. elevated_blood_urea_nitrogen_importance
9. tachycardia_importance
10. low_mean_arterial_pressure_importance
ìœ„ ë³€ìˆ˜ë“¤ì€ ê¸°ê´€ ë°œê´€ ì‹¤íŒ¨ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ì¤‘ìš”í•œ ë³€ìˆ˜ì¸ê°€? (ì£¼ì–´ì§„ í™˜ì ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”)

ì‘ë‹µ ê·œì¹™:
- ë§¤ìš° ì¤‘ìš”í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ê²½ìš°: 1
- ì¤‘ìš”í•˜ì§€ ì•Šê±°ë‚˜ ê´€ë ¨ì´ ì—†ëŠ” ê²½ìš°: 0:


ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "patients": [
    {{
      "obesity_importance": 0 or 1,
      "advanced_age_importance": 0 or 1,
      "male_sex_importance": 0 or 1,
      "high_fraction_of_inspired_oxygen_importance": 0 or 1,
      "diabetes_mellitus_history_importance": 0 or 1,
      "acidosis_importance": 0 or 1,
      "anemia_importance": 0 or 1,
      "elevated_blood_urea_nitrogen_importance": 0 or 1,
      "tachycardia_importance": 0 or 1,
      "low_mean_arterial_pressure_importance": 0 or 1,
    }}
  ]
}}

ì£¼ì˜: JSON í˜•ì‹ ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""

        print("\n\nğŸ¤– Calling LLM for ontology tagging...")

        # LLM í˜¸ì¶œ
        response = client.chat.completions.create(
            model=state["tagging_model"],
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì¤‘í™˜ìì‹¤ ì „ë¬¸ì˜ì´ì ì„ìƒ ë°ì´í„° ì „ë¬¸ê°€ì•¼. ì£¼ì–´ì§„ ë³€ìˆ˜ì˜ ì¤‘ìš”ë„ë¥¼ 1 ë˜ëŠ” 0ìœ¼ë¡œë§Œ í‰ê°€í•´ì¤˜."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        # LLM ì‘ë‹µ íŒŒì‹±
        llm_output = json.loads(response.choices[0].message.content)

        # ì˜¨í†¨ë¡œì§€ íŠ¹ì„± ì¶”ì¶œ
        ontology_features = {}
        feature_names = ['obesity_importance',
       'advanced_age_importance', 'male_sex_importance',
       'high_fraction_of_inspired_oxygen_importance',
       'diabetes_mellitus_history_importance', 'acidosis_importance',
       'anemia_importance', 'elevated_blood_urea_nitrogen_importance',
       'tachycardia_importance', 'low_mean_arterial_pressure_importance']

        for feature_name in feature_names:
            feature_values = [
                patient.get(feature_name, 0)
                for patient in llm_output["patients"]
            ]
            ontology_features[feature_name] = pd.Series(feature_values, dtype=int)
            print(f"Ontology feature: {feature_name}, Value: {feature_values}")

        # Feature matrix ìƒì„± (ì›ë³¸ ë°ì´í„° + ì˜¨í†¨ë¡œì§€ íŠ¹ì„±)
        feature_df = df.copy()
        for feature_name, feature_values in ontology_features.items():
            feature_df[feature_name] = feature_values

        feature_matrix = feature_df.values

        # Feature ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (ìˆœì„œ ìœ ì§€)
        feature_names_list = feature_df.columns.tolist()

        print(f"âœ“ LLM tagged {len(ontology_features)} ontology features")
        print(f"  Features: {', '.join(ontology_features.keys())}")

        return {
            **state,
            "ontology_features": ontology_features,
            "feature_matrix": feature_matrix,
            "feature_names": feature_names_list,
            "error": None
        }

    except Exception as e:
        return {
            **state,
            "error": f"Ontology tagging error: {str(e)}"
        }


# Node 3: ML ì˜ˆì¸¡ (ì‚¬ì „ í•™ìŠµëœ XGBoost ëª¨ë¸ ì‚¬ìš©)
def predict_extubation_failure(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """
    ì‚¬ì „ í•™ìŠµëœ XGBoost ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°œê´€ ì‹¤íŒ¨ í™•ë¥  ì˜ˆì¸¡
    """
    try:
        feature_matrix = state["feature_matrix"]
        model_path = "./models/best_model_medgemma.pkl"
        
        # ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(model_path):
            return {
                **state,
                "error": f"Model not found at {model_path}. Please train the model first."
            }

        # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
        model = joblib.load(model_path)
        print(f"\n\nâœ“ Loaded pre-trained model from {model_path}")


        feature_matrix = np.array(feature_matrix)
        
        # ëª¨ë¸ì—ì„œ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì»¬ëŸ¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        feature_names = model.input_feature_names

        # feature_matrixë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        feature_matrix = pd.DataFrame(feature_matrix, columns=feature_names if feature_matrix.shape[1] == len(feature_names) else None)
        
        predictions = model.predict_proba(feature_matrix)[:, 1]

        # í™•ë¥  ê°’ ì¶”ì¶œ (ì´ì§„ ë¶„ë¥˜ì˜ ê²½ìš°)
        failure_probability = float(predictions[0])
        predicted_class = 1 if failure_probability > 0.3 else 0

        print(f"âœ“ XGBoost Prediction: {failure_probability:.2%} failure probability")
        print(f"  Predicted class: {'ì‹¤íŒ¨ ì˜ˆìƒ' if predicted_class == 1 else 'ì„±ê³µ ì˜ˆìƒ'}")

        prediction_result = {
            "probability": failure_probability,
            "class": int(predicted_class)
        }

        return {
            **state,
            "model": model,
            "prediction_result": prediction_result,
            "error": None
        }

    except Exception as e:
        return {
            **state,
            "error": f"Prediction error: {str(e)}"
        }


# Node 4: SHAP Value ê³„ì‚°
def calculate_shap_values(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """
    SHAP (SHapley Additive exPlanations) ê°’ ê³„ì‚°
    ê° featureê°€ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë„ ë¶„ì„
    """
    try:
        model = state["model"]
        feature_matrix = state["feature_matrix"]
        feature_names = model.input_feature_names
    
        if model is None:
            return {
                **state,
                "error": "Model not found in state. Cannot calculate SHAP values."
            }
    
        print("\n\nğŸ” Calculating SHAP values...")
    
        # DMatrixë¡œ ë³€í™˜
        feature_matrix = np.array(feature_matrix)
    
        feature_names = model.input_feature_names
    
        # feature_matrixë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        feature_matrix = pd.DataFrame(feature_matrix, columns=feature_names if feature_matrix.shape[1] == len(feature_names) else None)
        
        preprocessor = model.named_steps.get("preprocess", None)  # ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        final_estimator = model.named_steps["model"]      # ë§ˆì§€ë§‰ ëª¨ë¸ ë‹¨ê³„
        feature_matrix_transformed = preprocessor.transform(feature_matrix)
    
        
        # SHAP explainer ìƒì„± ë° ê°’ ê³„ì‚°
        explainer = shap.TreeExplainer(final_estimator)
        shap_values = explainer.shap_values(feature_matrix_transformed)
        shap_values_sample = np.array(shap_values)[0,:,1]
        
        # Feature ì¤‘ìš”ë„ ì •ë¦¬
        shap_explanation = {
            "feature_importance": {
                name: float(shap_values_sample[i])
                for i, name in enumerate(feature_names)
            },
            "top_risk_factors": sorted(
                [(name, abs(float(shap_values_sample[i])))
                 for i, name in enumerate(feature_names)],
                key=lambda x: x[1],
                reverse=True
            )[:5]
        }
    
        print(f"âœ“ Calculated SHAP values for {len(feature_names)} features")
        print(f"  Top risk factor: {shap_explanation['top_risk_factors'][0][0]}")
        print(f"  Top 5 Risk factors: {shap_explanation['top_risk_factors']}")
    
        return {
            **state,
            "shap_values": shap_values,
            "shap_explanation": shap_explanation,
            "error": None
        }

    except Exception as e:
        return {
            **state,
            "error": f"SHAP calculation error: {str(e)}"
        }


# Node 5: ë³´í˜¸ì ì„¤ëª…ìš© ë ˆí¬íŠ¸ ìƒì„±
def generate_report(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ML ì˜ˆì¸¡ ê²°ê³¼ì™€ SHAP ê°’ì„ í™œìš©í•œ ë³´í˜¸ììš© ì„¤ëª… ë ˆí¬íŠ¸ ìƒì„±
    """
    try:
        prediction = state["prediction_result"]
        shap_exp = state["shap_explanation"]
        patient_input = state["patient_input"]

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(base_url="your_endpoint_url", api_key="your_api_key")

        # í™•ë¥  ê°’
        probability = prediction['probability']
        predicted_class = prediction['class']

        # ì£¼ìš” ìœ„í—˜ ìš”ì¸ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì¤€ë¹„
        top_risk_factors = []
        for factor, importance in shap_exp["top_risk_factors"]:
            # impact_direction = "ìœ„í—˜ë„ ì¦ê°€" if shap_exp["feature_importance"][factor] > 0 else "ìœ„í—˜ë„ ê°ì†Œ"
            top_risk_factors.append({
                "feature_name": factor,
                "importance_score": round(importance, 4),
                # "impact": impact_direction
            })

        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œì§„ê³¼ í™˜ì ë³´í˜¸ì ì‚¬ì´ì˜ ì†Œí†µì„ ë•ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì¸ê³µì§€ëŠ¥ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ë ˆí¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ì…ë ¥ ë°ì´í„°

### í™˜ì ì •ë³´
{json.dumps(patient_input, indent=2, ensure_ascii=False)}

### AI ì˜ˆì¸¡ ê²°ê³¼
- ë°œê´€(ì¸ê³µí˜¸í¡ê¸° íŠœë¸Œ ì œê±°) ì‹¤íŒ¨ í™•ë¥ : {probability:.1%}
- ì˜ˆì¸¡ í´ë˜ìŠ¤: {predicted_class} (0=ì•ˆì „, 1=ìœ„í—˜)

### ì£¼ìš” ìœ„í—˜ ìš”ì¸ (ì¤‘ìš”ë„ ìˆœìœ„)
{json.dumps(top_risk_factors, indent=2, ensure_ascii=False)}

## ë ˆí¬íŠ¸ ì‘ì„± ì§€ì¹¨

**ëª©ì **: ë³´í˜¸ìê°€ ë°œê´€(ì¸ê³µí˜¸í¡ê¸° íŠœë¸Œ ì œê±°) ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**í†¤ & ìŠ¤íƒ€ì¼**:
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”
- ë³´í˜¸ìì˜ ë¶ˆì•ˆê°ì„ ì´í•´í•˜ë©´ì„œë„ ì •í™•í•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”
- ì˜í•™ì  ì „ë¬¸ì„±ê³¼ ì¸ê°„ë¯¸ë¥¼ ê· í˜•ìˆê²Œ í‘œí˜„í•˜ì„¸ìš”

**ìš©ì–´ ì„ íƒ**:
- ì „ë¬¸ ì˜ë£Œ ìš©ì–´ëŠ” ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
  ì˜ˆ: "ë°œê´€/ì‚½ê´€" â†’ "í˜¸í¡ê´€ ì œê±°", "ì¸ê³µí˜¸í¡ê¸° íŠœë¸Œ ì œê±°"
  ì˜ˆ: "SPO2" â†’ "í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„" ë˜ëŠ” "ì‚°ì†Œ ìˆ˜ì¹˜"
  ì˜ˆ: "BMI" â†’ "ì²´ì§ˆëŸ‰ì§€ìˆ˜" ë˜ëŠ” "ë¹„ë§Œë„"
- Feature ì´ë¦„(ì˜ì–´ ë˜ëŠ” ì „ë¬¸ìš©ì–´)ì€ í•œê¸€ë¡œ ì˜ì—­í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”

**ì„¤ëª… ë°©ì‹**:
- í™•ë¥  ìˆ˜ì¹˜ë¥¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë¹„ìœ ë¡œ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
- ìœ„í—˜ ìš”ì¸ì´ ì™œ ì¤‘ìš”í•œì§€ ë³´í˜¸ì ì…ì¥ì—ì„œ ì„¤ëª…í•˜ì„¸ìš”
- ì˜ë£Œì§„ì˜ ëª¨ë‹ˆí„°ë§ê³¼ ì „ë¬¸ì  íŒë‹¨ì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•˜ì„¸ìš”

## ë ˆí¬íŠ¸ êµ¬ì„± (ë‹¤ìŒ ìˆœì„œë¡œ ì‘ì„±)

1. **ì¸ì‚¬ ë° ì†Œê°œ** (2-3ë¬¸ì¥)
   - ë”°ëœ»í•œ ì¸ì‚¬ì™€ ë ˆí¬íŠ¸ì˜ ëª©ì  ì„¤ëª…

2. **í™˜ì ìƒíƒœ ìš”ì•½** (3-4ë¬¸ì¥)
   - ì œê³µëœ í™˜ì ì •ë³´ë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ìš”ì•½
   - ê° ìˆ˜ì¹˜ê°€ ì •ìƒ ë²”ìœ„ì¸ì§€, ì£¼ì˜ê°€ í•„ìš”í•œì§€ ê°„ë‹¨íˆ ì„¤ëª…

3. **AI ì˜ˆì¸¡ ê²°ê³¼ í•´ì„** (4-5ë¬¸ì¥)
   - ì‹¤íŒ¨ í™•ë¥ ì´ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì‰½ê²Œ ì„¤ëª…
   - ì´ í™•ë¥ ì´ ë†’ì€ì§€ ë‚®ì€ì§€ ë§¥ë½ ì œê³µ
   - ì˜ˆì¸¡ì´ ì ˆëŒ€ì ì´ ì•„ë‹Œ ì°¸ê³ ìë£Œì„ì„ ëª…ì‹œ

4. **ì£¼ìš” ìœ„í—˜ ìš”ì¸ ìƒì„¸ ì„¤ëª…** (ê° ìš”ì¸ë‹¹ 2-3ë¬¸ì¥)
   - ìƒìœ„ 3-5ê°œ ìœ„í—˜ ìš”ì¸ì„ ì„ íƒí•˜ì—¬ ì„¤ëª…
   - ê° ìš”ì¸ì´ ì™œ ë°œê´€ ì„±ê³µ/ì‹¤íŒ¨ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì„¤ëª…
   - Feature ì´ë¦„ì„ ë³´í˜¸ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìš©ì–´ë¡œ ë³€í™˜

5. **ë§ˆë¬´ë¦¬ ë©”ì‹œì§€** (2ë¬¸ì¥)
   - ì•ˆì‹¬ê³¼ ê²©ë ¤ì˜ ë©”ì‹œì§€
   - ì˜ë£Œì§„ì˜ ì „ë¬¸ì„±ì— ëŒ€í•œ ì‹ ë¢° ê°•ì¡°

**ì¤‘ìš”**: ë ˆí¬íŠ¸ëŠ” ìˆœìˆ˜í•œ í•œê¸€ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ì„±í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì„œì‹(#, **, - ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ì„¹ì…˜ ì œëª©ì€ [ì„¹ì…˜ëª…] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.
"""

        print("\n\nğŸ¤– Calling LLM to generate patient-friendly report...")

        # LLM í˜¸ì¶œ
        response = client.chat.completions.create(
            model=state["generation_model"],
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
                               "ë³µì¡í•œ ì˜í•™ ì •ë³´ë¥¼ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ë©°, ë³´í˜¸ìê°€ ì˜¬ë°”ë¥¸ ì˜ë£Œ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤."
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )

        # LLMì´ ìƒì„±í•œ ë ˆí¬íŠ¸
        llm_report = response.choices[0].message.content

        # ë ˆí¬íŠ¸ í—¤ë”ì™€ í‘¸í„° ì¶”ê°€
        report = f"""
{'='*60}
ê¸°ê³„í™˜ê¸° ë°œê´€ ì•ˆë‚´ë¬¸
{'='*60}

ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}

{llm_report}

{'='*60}
ë³¸ ì•ˆë‚´ë¬¸ì€ AI ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
ìµœì¢… ì˜ë£Œ ê²°ì •ì€ ë‹´ë‹¹ ì˜ë£Œì§„ì˜ ì¢…í•©ì ì¸ íŒë‹¨ì— ë”°ë¼ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
ê¶ê¸ˆí•œ ì ì´ë‚˜ ìš°ë ¤ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì˜ë£Œì§„ì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.
{'='*60}
"""

        print("âœ“ Generated patient-friendly report using LLM")
        return {
            **state,
            "report": report,
            "error": None
        }

    except Exception as e:
        return {
            **state,
            "error": f"Report generation error: {str(e)}"
        }



# ì—ëŸ¬ í•¸ë“¤ëŸ¬
def handle_error(state: ExtubationPredictionState) -> ExtubationPredictionState:
    """ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬"""
    print(f"âœ— Error occurred: {state['error']}")
    return state


# ì¡°ê±´ë¶€ ì—£ì§€: ì—ëŸ¬ ì²´í¬
def check_error(state: ExtubationPredictionState) -> str:
    """ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ í•¸ë“¤ëŸ¬ë¡œ, ì—†ìœ¼ë©´ ë‹¤ìŒ ë…¸ë“œë¡œ"""
    if state.get("error"):
        return "error"
    return "continue"


# LangGraph êµ¬ì„±
def create_demo_graph():
    """ë°œê´€ ì‹¤íŒ¨ ì˜ˆì¸¡ ë°ëª¨ ê·¸ë˜í”„ ìƒì„±"""

    workflow = StateGraph(ExtubationPredictionState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("process_input", process_user_input)
    workflow.add_node("tag_ontology", tag_ontology_features)
    workflow.add_node("predict", predict_extubation_failure)
    workflow.add_node("calculate_shap", calculate_shap_values)
    workflow.add_node("generate_report", generate_report)
    workflow.add_node("handle_error", handle_error)

    # ì—£ì§€ ì¶”ê°€ (ìˆœì°¨ì  í”Œë¡œìš°)
    workflow.set_entry_point("process_input")

    # ì¡°ê±´ë¶€ ì—£ì§€: ê° ë‹¨ê³„ë§ˆë‹¤ ì—ëŸ¬ ì²´í¬
    workflow.add_conditional_edges(
        "process_input",
        check_error,
        {
            "continue": "tag_ontology",
            "error": "handle_error"
        }
    )

    workflow.add_conditional_edges(
        "tag_ontology",
        check_error,
        {
            "continue": "predict",
            "error": "handle_error"
        }
    )

    workflow.add_conditional_edges(
        "predict",
        check_error,
        {
            "continue": "calculate_shap",
            "error": "handle_error"
        }
    )

    workflow.add_conditional_edges(
        "calculate_shap",
        check_error,
        {
            "continue": "generate_report",
            "error": "handle_error"
        }
    )

    workflow.add_edge("generate_report", END)
    workflow.add_edge("handle_error", END)

    return workflow.compile()


# ì‹¤í–‰ í•¨ìˆ˜
def run_demo_prediction(patient_input: dict, tagging_model: str, generation_model: str):
    """
    ë°œê´€ ì‹¤íŒ¨ ì˜ˆì¸¡ ë°ëª¨ ì‹¤í–‰ (ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜)

    Args:
        patient_input: í™˜ì ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            ì˜ˆì‹œ: {
                "AGE": 72,
                "BMI": 28.5,
                "SPO2": 88,
                "HEART_RATE": 105,
                "SYSTOLIC_BP": 145
            }

    Returns:
        ìµœì¢… ìƒíƒœ (ì˜ˆì¸¡ ê²°ê³¼, SHAP ê°’, ë ˆí¬íŠ¸ í¬í•¨)
    """
    graph = create_demo_graph()

    initial_state = {
        "patient_input": patient_input,
        "tagging_model": tagging_model,
        "generation_model": generation_model,
        "patient_data": None,
        "ontology_features": None,
        "feature_matrix": None,
        "feature_names": None,
        "model": None,
        "prediction_result": None,
        "shap_values": None,
        "shap_explanation": None,
        "report": None,
        "error": None
    }

    print("\n" + "="*60)
    print("ë°œê´€ ì‹¤íŒ¨ ì˜ˆì¸¡ ë°ëª¨ ì‹œì‘")
    print("="*60 + "\n")

    final_state = graph.invoke(initial_state)

    if final_state.get("report"):
        print(final_state["report"])

    return final_state


# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
def get_user_input():
    """
    í„°ë¯¸ë„ì—ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ í™˜ì ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
    """
    print("\n" + "="*60)
    print("í™˜ì ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    print("="*60)

    # ì˜ˆì‹œì…ë‹ˆë‹¤
    try:
        age = float(input("ë‚˜ì´ (AGE): "))
        bmi = float(input("BMI: "))
        spo2 = float(input("ì‚°ì†Œí¬í™”ë„ (SPO2, %): "))
        heart_rate = float(input("ì‹¬ë°•ìˆ˜ (HEART_RATE, íšŒ/ë¶„): "))
        systolic_bp = float(input("ìˆ˜ì¶•ê¸° í˜ˆì•• (SYSTOLIC_BP, mmHg): "))

        patient_input = {
            "AGE": age,
            "BMI": bmi,
            "SPO2": spo2,
            "HEART_RATE": heart_rate,
            "SYSTOLIC_BP": systolic_bp
        }

        return patient_input

    except ValueError as e:
        print(f"âœ— ì…ë ¥ ì˜¤ë¥˜: ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. ({e})")
        return None


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ë°œê´€ ì‹¤íŒ¨ ì˜ˆì¸¡ ë°ëª¨ ì‹œìŠ¤í…œ")
    # ì˜µì…˜ 1: ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì‹¤í–‰
    # patient_input = get_user_input()

    # ì˜µì…˜ 2: í•˜ë“œì½”ë”©ëœ ì˜ˆì‹œ ë°ì´í„°ë¡œ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    patient_input = {'AGE': 82,
 'SEX': 'F',
 'BMI': 32.55668934,
 'VENT_DUR': 149.8666667,
 'CHF': 0,
 'CVD': 0,
 'CPD': 1,
 'CKD': 0,
 'CLD': 1,
 'DM': 1,
 'CRRT': 0,
 'CVP': 6.3,
 'MAP': 61.1,
 'HR': 93.0,
 'RR': 17.0,
 'BT': 93.4,
 'SPO2': 92.0,
 'GCS': 11.0,
 'PH': 7.5,
 'PACO2': 47.0,
 'PAO2': 115.1,
 'HCO3': 28.2,
 'LACTATE': 0.89,
 'WBC': np.nan,
 'HB': np.nan,
 'PLT': np.nan,
 'SODIUM': 136.1,
 'POTASSIUM': 3.1,
 'CHLORIDE': 102.0,
 'BUN': 23.0,
 'CR': 1.4,
 'TB': np.nan,
 'PT': np.nan,
 'FIO2': 40.2,
 'PEEP': 5.1,
 'PPLAT': np.nan,
 'TV': 620.0,
 'obesity_importance': 1,
 'advanced_age_importance': 1,
 'male_sex_importance': 1,
 'high_fraction_of_inspired_oxygen_importance': 1,
 'diabetes_mellitus_history_importance': 1,
 'acidosis_importance': 0,
 'anemia_importance': 0,
 'elevated_blood_urea_nitrogen_importance': 1,
 'tachycardia_importance': 1,
 'low_mean_arterial_pressure_importance': 1}

    ALLOWED_MODELS = ["gpt-oss-20b", "hari-q3", "medgemma-27b-text-it"]
    tagging_model = "medgemma-27b-text-it"
    generation_model = "medgemma-27b-text-it"
    
    assert tagging_model in ALLOWED_MODELS, f"Unknown tagging model name: {tagging_model}"
    assert generation_model in ALLOWED_MODELS, f"Unknown generation model name: {generation_model}"
    
    if patient_input:
        result = run_demo_prediction(patient_input, tagging_model, generation_model)

        # ê²°ê³¼ ì ‘ê·¼
        if result.get("prediction_result"):
            print(f"\nìµœì¢… ì˜ˆì¸¡: {result['prediction_result']}")

        if result.get("error"):
            print(f"\nì—ëŸ¬ ë°œìƒ: {result['error']}")
